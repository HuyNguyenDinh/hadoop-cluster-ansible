---
# tasks file for hadoop role

# 1. Create Hadoop group
- name: Create Hadoop group
  ansible.builtin.group:
    name: "{{ hadoop_group }}"
    state: present

# 2. Create service users
- name: Create HDFS user
  ansible.builtin.user:
    name: "{{ hdfs_user }}"
    group: "{{ hadoop_group }}"
    create_home: yes
    shell: /bin/bash
    state: present

- name: Create YARN user
  ansible.builtin.user:
    name: "{{ yarn_user }}"
    group: "{{ hadoop_group }}"
    create_home: yes
    shell: /bin/bash
    state: present

- name: Create MapReduce user
  ansible.builtin.user:
    name: "{{ mapred_user }}"
    group: "{{ hadoop_group }}"
    create_home: yes
    shell: /bin/bash
    state: present

# 3. Generate SSH keys and distribute for hdfs user
- name: Generate SSH key for hdfs user on master node
  ansible.builtin.user:
    name: "{{ hdfs_user }}"
    generate_ssh_key: yes
    ssh_key_bits: 4096
    ssh_key_type: rsa
  when: inventory_hostname == groups['master'][0]

- name: Fetch hdfs user's public key from master node
  ansible.builtin.fetch:
    src: "/home/{{ hdfs_user }}/.ssh/id_rsa.pub"
    dest: "hdfs_id_rsa.pub"
    flat: yes
  when: inventory_hostname == groups['master'][0]

- name: Create .ssh directory for hdfs user
  ansible.builtin.file:
    path: "/home/{{ hdfs_user }}/.ssh"
    state: directory
    owner: "{{ hdfs_user }}"
    group: "{{ hadoop_group }}"
    mode: '0700'

- name: Distribute hdfs public key to authorized_keys
  ansible.builtin.copy:
    src: "hdfs_id_rsa.pub"
    dest: "/home/{{ hdfs_user }}/.ssh/authorized_keys"
    owner: "{{ hdfs_user }}"
    group: "{{ hadoop_group }}"
    mode: '0600'


- name: Ensure .ssh directory exists for hdfs user
  ansible.builtin.file:
    path: "/home/{{ hdfs_user }}/.ssh"
    state: directory
    owner: "{{ ansible_user_name }}"
    group: "{{ ansible_user_name }}"
    mode: '0700'

- name: Add all hosts to hdfs user's known_hosts
  ansible.builtin.known_hosts:
    path: "/home/{{ hdfs_user }}/.ssh/known_hosts"
    name: "{{ hostvars[item]['ansible_host'] }}"
    key: "{{ lookup('pipe', 'ssh-keyscan -H -T 5 ' + hostvars[item]['ansible_host']) }}"
  with_items: "{{ groups['all'] }}"
  become: yes

- name: Ensure .ssh directory exists for hdfs user
  ansible.builtin.file:
    path: "/home/{{ hdfs_user }}/.ssh"
    state: directory
    owner: "{{ hdfs_user }}"
    group: "{{ hadoop_group }}"
    mode: '0700'

# 4. Generate SSH keys and distribute for yarn user
- name: Generate SSH key for yarn user on master node
  ansible.builtin.user:
    name: "{{ yarn_user }}"
    generate_ssh_key: yes
    ssh_key_bits: 4096
    ssh_key_type: rsa
  when: inventory_hostname == groups['master'][0]

- name: Fetch yarn user's public key from master node
  ansible.builtin.fetch:
    src: "/home/{{ yarn_user }}/.ssh/id_rsa.pub"
    dest: "yarn_id_rsa.pub"
    flat: yes
  when: inventory_hostname == groups['master'][0]

- name: Create .ssh directory for yarn user
  ansible.builtin.file:
    path: "/home/{{ yarn_user }}/.ssh"
    state: directory
    owner: "{{ yarn_user }}"
    group: "{{ hadoop_group }}"
    mode: '0700'

- name: Distribute yarn public key to authorized_keys
  ansible.builtin.copy:
    src: "yarn_id_rsa.pub"
    dest: "/home/{{ yarn_user }}/.ssh/authorized_keys"
    owner: "{{ yarn_user }}"
    group: "{{ hadoop_group }}"
    mode: '0600'

- name: Ensure .ssh directory exists for yarn user
  ansible.builtin.file:
    path: "/home/{{ yarn_user }}/.ssh"
    state: directory
    owner: "{{ ansible_user_name }}"
    group: "{{ ansible_user_name }}"
    mode: '0700'

- name: Add all hosts to yarn user's known_hosts
  ansible.builtin.known_hosts:
    path: "/home/{{ yarn_user }}/.ssh/known_hosts"
    name: "{{ hostvars[item]['ansible_host'] }}"
    key: "{{ lookup('pipe', 'ssh-keyscan -H -T 5 ' + hostvars[item]]['ansible_host']) }}"
  with_items: "{{ groups['all'] }}"
  become: yes

- name: Ensure .ssh directory exists for yarn user
  ansible.builtin.file:
    path: "/home/{{ yarn_user }}/.ssh"
    state: directory
    owner: "{{ yarn_user }}"
    group: "{{ hadoop_group }}"
    mode: '0700'

# 5. Download and install Hadoop
- name: Download Hadoop tarball
  ansible.builtin.get_url:
    url: "{{ hadoop_download_url }}"
    dest: "/tmp/hadoop-{{ hadoop_version }}.tar.gz"
    mode: '0644'

- name: Extract Hadoop tarball
  ansible.builtin.unarchive:
    src: "/tmp/hadoop-{{ hadoop_version }}.tar.gz"
    dest: /opt/
    remote_src: yes
    creates: "/opt/hadoop-{{ hadoop_version }}"

- name: Create symlink to Hadoop installation directory
  ansible.builtin.file:
    src: "/opt/hadoop-{{ hadoop_version }}"
    dest: "{{ hadoop_install_dir }}"
    state: link
    force: yes

- name: Change ownership of Hadoop installation directory
  ansible.builtin.file:
    path: "{{ hadoop_install_dir }}"
    owner: "{{ hdfs_user }}"
    group: "{{ hadoop_group }}"
    recurse: yes
    state: directory

# 6. Configure Hadoop environment and files
- name: Copy hadoop-env.sh
  ansible.builtin.template:
    src: hadoop-env.sh.j2
    dest: "{{ hadoop_conf_dir }}/hadoop-env.sh"
    owner: "{{ hdfs_user }}"
    group: "{{ hadoop_group }}"
    mode: '0644'

- name: Configure core-site.xml
  ansible.builtin.template:
    src: core-site.xml.j2
    dest: "{{ hadoop_conf_dir }}/core-site.xml"
    owner: "{{ hdfs_user }}"
    group: "{{ hadoop_group }}"
    mode: '0644'

- name: Configure hdfs-site.xml
  ansible.builtin.template:
    src: hdfs-site.xml.j2
    dest: "{{ hadoop_conf_dir }}/hdfs-site.xml"
    owner: "{{ hdfs_user }}"
    group: "{{ hadoop_group }}"
    mode: '0644'

- name: Configure mapred-site.xml
  ansible.builtin.template:
    src: mapred-site.xml.j2
    dest: "{{ hadoop_conf_dir }}/mapred-site.xml"
    owner: "{{ mapred_user }}"
    group: "{{ hadoop_group }}"
    mode: '0644'

- name: Configure yarn-site.xml
  ansible.builtin.template:
    src: yarn-site.xml.j2
    dest: "{{ hadoop_conf_dir }}/yarn-site.xml"
    owner: "{{ yarn_user }}"
    group: "{{ hadoop_group }}"
    mode: '0644'

# 7. Create necessary directories
- name: Create Hadoop temporary directory
  ansible.builtin.file:
    path: "{{ hadoop_tmp_dir }}"
    owner: "{{ hdfs_user }}"
    group: "{{ hadoop_group }}"
    mode: '0755'
    state: directory

- name: Create HDFS directories
  ansible.builtin.file:
    path: "{{ item }}"
    owner: "{{ hdfs_user }}"
    group: "{{ hadoop_group }}"
    mode: '0755'
    state: directory
  loop:
    - "{{ namenode_dir }}"
    - "{{ datanode_dir }}"

- name: Create YARN local and log directories
  ansible.builtin.file:
    path: "{{ item }}"
    owner: "{{ yarn_user }}"
    group: "{{ hadoop_group }}"
    mode: '0755'
    state: directory
  loop:
    - "/var/hadoop/yarn/local"
    - "/var/hadoop/yarn/logs"

- name: Create MapReduce history directory
  ansible.builtin.file:
    path: "{{ hadoop_install_dir }}/history"
    owner: "{{ mapred_user }}"
    group: "{{ hadoop_group }}"
    mode: '0755'
    state: directory

# 8. Ensure service users own their home directories
- name: Ensure hdfs user owns their home directory
  ansible.builtin.file:
    path: "/home/{{ hdfs_user }}"
    owner: "{{ hdfs_user }}"
    group: "{{ hadoop_group }}"
    state: directory

- name: Ensure yarn user owns their home directory
  ansible.builtin.file:
    path: "/home/{{ yarn_user }}"
    owner: "{{ yarn_user }}"
    group: "{{ hadoop_group }}"
    state: directory

- name: Ensure mapred user owns their home directory
  ansible.builtin.file:
    path: "/home/{{ mapred_user }}"
    owner: "{{ mapred_user }}"
    group: "{{ hadoop_group }}"
    state: directory

- name: Copy workers file to master node
  ansible.builtin.template:
    src: workers.j2
    dest: "{{ hadoop_conf_dir }}/workers"
    owner: "{{ hdfs_user }}"
    group: "{{ hadoop_group }}"
    mode: '0644'
  when: inventory_hostname == groups['master'][0]

# 8.1. Create logs directory for Hadoop services
- name: Create logs directory
  ansible.builtin.file:
    path: "{{ hadoop_install_dir }}/logs"
    owner: "{{ hdfs_user }}"
    group: "{{ hadoop_group }}"
    mode: '0755'
    state: directory

# 9. Format Namenode (only on master)
- name: Format Namenode (only on master)
  ansible.builtin.command:
    cmd: "{{ hadoop_install_dir }}/bin/hdfs namenode -format -force"
  when: inventory_hostname == groups['master'][0]
  become: yes
  become_user: "{{ hdfs_user }}"

# 10. Adjust ownership for Hadoop directories
- name: Set ownership for Hadoop directories
  ansible.builtin.file:
    path: "{{ item }}"
    owner: "{{ hdfs_user }}"
    group: "{{ hadoop_group }}"
    state: directory
    recurse: yes
  loop:
    - "{{ hadoop_install_dir }}"
    - "{{ hadoop_tmp_dir }}"
    - "{{ namenode_dir }}"
    - "{{ datanode_dir }}"
    - "/var/hadoop/yarn"
    - "/var/hadoop/yarn/local"
    - "/var/hadoop/yarn/logs"
